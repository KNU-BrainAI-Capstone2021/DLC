#20210312 1차 오프라인 회의
개괄적인 내용을 배워서 아직 주제를 정하기 어렵다.
수업에서 배운 자율주행
물체 인식/ 페이지 변형(내용이 적합한가 판단 후)
구문이나 필체를 인식시켜 글을 쓰게 한다/ 맞춤법 검사
코인이나 주식 > 차트 입력으로 다음 결과를 예상 후 대응하는 것
스포츠 매치 승률 > 선수, 전적 등을 근거로 판단
롤의 헬퍼/ 핵
롤토체스 > 덱 조합법으로 상대를 공략
               -입력값이 랜덤(우선적인 가중치를 부여해 순서를 정한다)
               -전적분석 사이트 등을 통해 학습
////
역할분담
메인함수는 다같이
내장함수는 따로 코딩
////
프로젝트 질문사항
학습을 할 때 여러번 코딩하는 과정을 거치는가
이전에 한 사람의 프로젝트 주제?
주제의 방향성
2학기는 어떠한 방향


#20210319 2차 온라인 회의
가중치가 다른 점을 활용
심리검사(ex mbti 등)/ 면접등에서 시뮬레이션 답변
어떠한 단어 선택이 면접 성공에 도움을 주는지 판단
//
주제 관련 질문 방식
//
24일 수요일 오후 5시 IT2-245 교수님 면담 예정

#2021324 교수님 1차 면담 
mediapipe, yolo, tensorflow 등의 패키지에 관해
딥러닝의 분야인 visual(pose, object) / nlp(자연어처리)  등


#20210329 3차 온라인 회의

참고 자료
https://lovit.github.io/nlp/2019/04/30/textrank/
https://excelsior-cjh.tistory.com/93
텍스트 키워드 추출
https://d2.naver.com/helloworld/8344782
글자 인식 예시
https://github.com/nilboy/pixel-recursive-super-resolution
픽셀 복원(Pixel Recursive Super Resolution)
https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix
https://paperswithcode.com/area/computer-vision
cctv
https://github.com/ivaibhavkr/Weapon-Detection-A
https://github.com/Ank-Cha/Social-Distancing-Analyser-COVID-19

가상 피팅 시스템
관상찾기
쓰레기 무단투기 예방
: 손에 든 물체를 두고가는것,
  사람이랑 물체가 일정 거리 이상 떨어지게 되면 투기로 판단
무인 점포

#20210402 교수님 2차 면담
쓰레기 무단투기 : 쓰레기를 특정지을 수 있는 방법 모호, 단순 쓰레기 투기에 관해서만 프로젝트를 진행한다면 너무 단순
무인 점포 : 실제 적용할 시 이점이 크지 않음
cctv관련 : 너무 어렵고 현재 상용화된 기술이므로 x
과제 관련 교수님 링크
https://www.youtube.com/watch?v=-Ff-yq7qquc

*스타일러(가제)*
자동 코디 프로그램
+가능하다면 3d로 구현
  온도 /기온 등에 맞춰 옷을 추천
1학기에는 오브젝트를 이해, 단순한 구현을 목적
- 옷을 사람의 몸에 맞추는것을 목표
2학기/ 방학을 이용해 스타일러 구현

발표
개념적인 부분에 대해 서술
시각적으로 보이는 결과 활용 시 이점
(코딩, 결과값 등)
1.
주제 - 주제 선정이유
이를 위해 오브젝트 디텍션이 필요하다.
오픈소스 플랫폼을 고민 후 yolo 채택 - 이유
이를 통해 ~한 과정으로 진행할 예정
1학기 / 2학기 계획 수립

#20210408 4차 온라인 회의
github readme 작성
yolo의 장점 ap(실시간 object 인식속도 빠름)

참고자료
https://curiousily.com/posts/object-detection-on-custom-dataset-with-yolo-v5-using-pytorch-and-python/
https://youtu.be/mQXOnOdhSOk
https://www.youtube.com/watch?v=hL-gJXgscOc
https://www.youtube.com/watch?v=NM6lrxy0bxs
https://better-today.tistory.com/3
https://www.notion.so/2021-1-82e40203335241c68241a40623c70f12

#20210504 5차 오프라인 회의
중간고사 이후 계획 수립
10주차 발표를 위한 ppt, 대본 제작
yolo를 통해 object detection 간단한 코드 구현

참고자료
https://youtube.com/watch?v=I0RVlki14gI&feature=share
https://youtu.be/N7XyqfhY2lU
https://youtube.com/watch?v=vHs51esvpg0&feature=share
https://bong-sik.tistory.com/16

#20210505 6차 온라인 회의
10주차 발표 개선, 수정, 예상 질문 정리
- 주차 별 계획, 물체인식 이론 등을 추가
- ppt 다듬기

참고자료
https://youtu.be/y03Nbv71CoU

#20210507 10주차 발표
아이디어나 내용에 관한 내용 줄이기
실제로 활동한 내용 발표
깃허브를 여러 사람이서 작성

#20210509 7차 온라인 회의
깃허브에 yolo 테스트 코드, 패키지 업로드
회의록 수정
11차 발표를 위한 ppt, 대본 제작

참고자료
https://twoicefish-secu.tistory.com/121

#20210512 11주차 발표
질문사항
혹시 Object detection 모델에  RCNN Faster RCNN, Yolov1 ~v4까지 엄청 많은데 Yolo의 어떤 점 때문에 프로젝트에서 사용한는 지 이유를 설명 해주실수있을까요?
저는 옷이나 패션 조합을 추천을 해주는 독자적인 알고리즘이 있어야 할 것 같은데 이에 대한 계획이 있으신지 궁금합니다!! 생각해두신 추천 방식이라던가 그런것들이 있으신지 궁금합니다!!
1학기에는 object detection을 수행하고, 2학기에는 옷 사진으로 피팅을 하신다고 하셨는데, 전신 사진과 옷 사진의 합성을 하는 문제를 어떻게 수행하실지 궁금합니다. (모델, 데이터셋 등)
혹시 헤드는 yolo로 detector를 사용하시는데 백본에서는 어떤 모델을 사용하실지 선정된건 있을까요?
피팅의 퀄리티를 위해서 단순 detection 뿐만 아니라 depth estimation 등의 방법을 활용해서 3d 정보를 뽑아내야 할 것이라고 생각하는데 이에 대해선 어떻게 생각하시나요?
각 구문이 어떠한 역할을 하며 가장 중요한 부분은? blob 명령어는 어떠한 것인가?

#20210515 8차 온라인 회의
Faster RCNN, YOLO, SSD
CornerNet, CenterNet 에 대한 구현/ 비교
깃허브 업로드 및 수정
faster rcnn, yolo, ssd 선정 후 비교
각각에 대한 알고리즘 설명/ 비교
~한 이유로 ? 선정 
dataset에 관한 내용 추가 여부
-> 옷에 landmark를 구현하는 것 관련해서 교수님께 질문 후 결정

참고자료
https://ultrakid.tistory.com/22
https://kuklife.tistory.com/123
https://youtu.be/XNRzZkZ-Byg
https://github.com/sejongresearch/FlowerClassification/issues/18
https://jetsonaicar.tistory.com/12
https://liuziwei7.github.io/projects/FashionLandmarks.html
https://github.com/svip-lab/HRNet-for-Fashion-Landmark-Estimation.PyTorch
https://junjiwon1031.github.io/2017/09/08/Single-Shot-Multibox-Detector.html
https://blog.lunit.io/2017/06/01/r-cnns-tutorial/

#20210519 9차 온라인 회의
0515에 상의한 내용을 바탕으로 ppt 제작
기본적으로 object detection에 대해 설명 -backbone, neck, head
detector인 faster rcnn, ssd, yolo를 1-stage, 2-stage를 나누어 기본 개념 설명
각 모델에 대해 동일한 사진으로 detection 결과와 시간을 기록
논문에 기재된 그래프를 바탕으로 실제 실행 시간과 비교하여 메인 모델 선정
yolov3를 선정하였고, 그 이유를 설명
이후 deepfashion2를 yolov3에 학습시켜 옷 데이터를 탐지하려고 함

참고자료
https://arxiv.org/abs/1612.03144
https://velog.io/@hewas1230/ObjectDetection-Architecture
https://nuggy875.tistory.com/20
https://kimcando94.tistory.com/115
https://wordbe.tistory.com/entry/MMDetection-%EB%85%BC%EB%AC%B8-%EC%A0%95%EB%A6%AC-%EB%B0%8F-%EB%AA%A8%EB%8D%B8-%EA%B5%AC%ED%98%84
https://ropiens.tistory.com/33
https://velog.io/@hewas1230/ObjectDetection-Architecture
https://yeomko.tistory.com/17
https://leechamin.tistory.com/221
http://incredible.ai/deep-learning/2018/03/17/Faster-R-CNN/
https://debuggercafe.com/faster-rcnn-object-detection-with-pytorch/
https://towardsdatascience.com/faster-rcnn-object-detection-f865e5ed7fc4
https://blog.lunit.io/2017/06/01/r-cnns-tutorial/
https://ganghee-lee.tistory.com/37
https://herbwood.tistory.com/15
https://taeu.github.io/paper/deeplearning-paper-ssd/
https://junjiwon1031.github.io/2017/09/08/Single-Shot-Multibox-Detector.html
https://cv-tricks.com/object-detection/faster-r-cnn-yolo-ssd/
https://paperswithcode.com/dataset/deepfashion2

#20210520 10차 온라인 회의
21일 발표를 위한 마무리, 다듬기

#20210521 12주차 발표
깃허브 커밋 더 자주
git을 통해 업로드 할때, master를 main으로 변경하는 법
다음 발표에는 deepfashion2에 대한 실습 결과 추가

#20210524 11차 온라인 회의
deepfashion2의 weight파일을 yolov3를 통해 실험
미리 학습된 데이터를 yolo를 통해 탐지하는 것
10/15 성공, 5/15 실패
현재 weight파일은 15000개의 실습을 통해 모델을 탐지하였으므로,
학습이 부족한 것은 아닐까라고 판단하여 이후 과정에서 
putty server를 이용하여 직접 학습시켜보자는 방향으로 프로젝트 진행
사용을 위해 putty 설치 이후 가상환경 dlc 제작, 현재 깃허브에 올라온 코드 server 
실습 내용을 바탕으로 13주차 발표자료 제작



참고자료
https://github.com/simaiden/Clothing-Detection
https://drive.google.com/drive/folders/1b7laIv9-oeh59XSV6aOO50eMKbTGsPoP

#20210527 13주차 발표
yolo는 detecting에 한계점을 가진다.
따라서 이 한계점을 넘어가는 외투나 코트 등등의 의상을 인식하기 못했을 가능성이 크다.
background와 detecting 대상의 색이 같을 경우 landmark를 정확하게 판단하기 어려울 수 있다.
최종적으로 dlc가 가고자 하는 목표에는 3d데이터나 음영을 가진 옷 데이터를 사용해야 되므로 
yolo이외의 다른 모델을 사용하는것을 추천한다.
yolo로 프로젝트 detector를 결정할때 사용한 weight파일과 deepfashion의 weight파일이 다르므로 학습할 때 어떠한
데이터를 사용했는지 분별하기 힘들다.

이러한 문제점들을 해결하기 위해 제시된 방안 
1. 더 많은 데이터를 학습
2. test데이터의 사진 사이즈를 통일시킨다.
3. opencv의 반전 기능을 이용하여 gray등으로 색을 변경시킨다.
 -> 변경하였을 때, 결과물이 원본에 detecting 결과를 추가한 것인지, 변경된 색에 결과를 더한 것인지에 대해
    정확한 판단이 필요하다. 변경된 색으로 결과가 나타난다면 의미있는 detecting x
4. 테스트 빈도를 늘려 정확도를 높인다(목표는 90%이상)
5. 모델을 변경한다(yolo는 영상에서 detecting하는데 더 적합=동적인 모델에서 detecting에 유리)

+코드보단 결과나 그래프, 플로우 차트, 모델링 등에 대해 중점적으로 다루기
 깃허브 커밋을 확인하기 위해 아이디가 보이게 readme 수정
 코드에 주석 등을 달기
 
 #20210530 12차 온라인 회의

fail 추정 이유
deepfashion2 데이터는 대부분 사람이 착용하고 있는 모습이므로 옷 그 자체는 잘 인식하지 못할 수 있는데, 이렇게 생각하는 것이 타당한가?
-> darknet에 학습시킬 데이터셋(deepfashion2)의 양을 늘리려고 하나 yolo에 해당하는 label 파일이 없어 이를 변환하는 과정이 필요, 데이터의 양을 늘려도 해결이 되지 않는다면 사용할 데이터셋을 변경하거나 모델을 변경할 계획

yolo의 문제? deepfashion의 문제?
->모델을 변경하고자 하나, 외장 그래피카드가 없어 서버를 사용해야 하나 cv2오류가 발생, opencv2를 설치하고 import해봐도 그대로 현상유지

테스트 데이터의 입력 사이즈를 통일하면 결과가 좋아지는가?
->사이즈는 blob을 통해 이미 리사이즈 된것으로 추정

색 반전을 통해 landmark를 잡고 detecting을 할 수 있는가?
opencv의 색 반전의 경우 결과값까지 반전이 유지되고, landmark를 따는 과정 자체가 힘들기 때문에 적용 방법을 모르겠다.

이를 해결하기 위해 20210531에 조교님에게 조언을 듣기로 함.

1. 다크넷을 학습시키는법
2. 이를 리눅스 스파이더에 적용하는 법
3. 실습 내용을 보여드리며 데이터셋의 문제인지 yolo의 문제인지 조교님 의견
4. 새로운 데이터셋을 구성할 때 yolo에 맞는 txt파일로 변환하는 법에 대해
5. 이를 통해 구성할 수 있는 발표 내용, 흐름


#20210531 13차 오프라인 회의
큰 기준점 4가지로 나누어 발표를 구성

환경 : 리눅스나 각자
 
model : yolo를 사용하는 방향
yolo의 특징인 빠른 탐색과 역동적인 환경에서 더 잘 detection 할 수 있다는 것을 이용하여 어느정도 발표를 구성
사진의 경우, 단순한 사진만 있는 경우보다 사람이 착용한 경우만 생각하는 방향으로 프로젝트를 진행하는게 어떨까.
확실하게 정해지면, 세부적인 계획를 세워 이를 발표에서 상세하게 프로젝트 방향을 설명 

dataset : dataset에 labelling하여 하는 과정이 복잡하다. 엑셀을 활용하여 ordering한 다음 csv파일을 대입하여 할 수 있지만, 현재 조교님은 추천하지 않는다. 현재 사용하고 있는 deepfashion2를 유지
json파일을 변환하는 것은 가능. 

결과 도출: 조원을 모델로 하여 여러가지 옷을 종류에 맞게 인식하는지 실제 적용가능성을 확인. 테스트 데이터량을 늘려 확실하게 결과를 도출. 20개 테스트는 너무 적다.
테스트 과정에서 옷 입은 사진과 옷만 있는 사진의 테스트를 늘려 비교하는것도 충분히 좋은 방법
힌 옷의 경우, 여러 필터를 적용해보았으나 detecting이 실패하였고, grayscale의 경우 변수에 관한 차원이 달라 실질적인 적용은 어렵다고 판단
코드에 for문을 이용한 반복문으로 한번에 많은 테스트를 진행할 수 있도록한다.


코드와 같이 시각적으로 좋지 못한 자료는 거의 배제하고, 현재의 결과나 뱡향성에 대해 집중하여 발표 구성. 실패 또는 잘 안된 부분에 대해서 말하되, 이러한 부분이 많아진다면 발표가 루즈해질 수 있으므로 적당히
최종발표는 현재까지의 진행과, 방향성에 대해서 다루는 것으로
발표 이전 정해진 교수님과의 미팅은 없을 것 같으며, 발표자료 구성 후 한번 더 조교님 피드백 받을 예정
+ 옷을 추천을 받는다고 할때, 이 기준은 주관적인 것이고 해석할 수 있는 여지가 많기 때문에 딥러닝의 범위를 벗어날 수 있다.
  그래서 나온 아이디어는 어느 정도 색을 입력받거나, 특정 조합을 배제하거나, 특정 옷을 미리 조합하여 생각하는 쪽
  어렵다고 판단된다면, numpy의 난수발생을 통해 랜덤하게 옷을 추천하는것도 나쁘지 않은 방법
  
#20210619 14차 온라인 회의
발표 개요

최종 결과 :
1) test data를 늘리고 정확성을 높인다.
2) bounding box를 추출한 뒤, 추출한 사진의 배경을 지워 옷 데이터를 추출한다.
3) 조원들 사진을 대입하여 detection 여부를 확인한다.
달성도 : 초기 15주차에서 의상을 잘라내어 저장하는것 까지 목표하였고, 완전하게 이루진 못했다.
이유는 ~
보완점 : 잘 해결되지 않은 부분에 대한 원인 파악, 이를 위한 방안
~
프로젝트 자체 평가 : B 
이후 2학기와 방학에 진행할 내용에 관해 설명 : 목표를 구현하기 위한 과정 

bounding box를 추출하여 배경을 제거, 이를 통해 옷을 추출하는 것을 구현
옷만 있는 사진은 가능하나, 사람이 입고 있거나 배경이 복잡한 사진은 불가능
->landmark를 통해 옷을 추출하는 것이 아닌 단순 색차이를 통한 추출이므로

테스트 데이터량을 늘리고, 포즈나 구도를 선별하는 과정을 통해 정확성을 높이려고 한다.


#20210620 15차 온라인 회의
발표를 위한 ppt,대본 제작
조원들이 직접 모델이 되어 테스트 데이터를 제작하였고, 이를 대입하여
detection이 가능한 사진의 구도나 환경에 대해서 추론함
세부적인 향후 계획에 대한 논의
최종발표 전 가능하다면 조교님 피드백을 통해 부족한 점 보완


#20210729 16차 온라인 회의
grabcut을 사용한 배경 제거 제시
detecting box를 통해 옷 추출, 분류 과정
-> 누끼를 따 옷 자체를 추출
-> landmark를 따서 하는 것보다 조금더 섬세한 작업
-> 필터링, 색반전, 배경 제거 등을 통해서 옷 자체를 추출
-> 옷의 landmark를 지정하여 코디에 필요한 데이터 제작
-> 신체 정보를 입력받거나 특정하여 아바타를 생성
-> 아바타의 신체 조건에 맞게 옷 데이터의 사이즈 등을 변경
-> 구현

#20210806 17차 온라인 회의
mediapipe 도입 결정, 기존 어플을 참고하여 배경 제거 방식 참고
배경제거 이후 옷의 landmark
 : mediapipe의 landmark와 결합->옷에도 적용가능한지 여부
resize를 위한 방법
아바타에 수치를 입력할 때, 센서 등을 이용할 수 있다면 이를 통해 데이터 추출, 이를 저장하여 하나의 아바타를 생성
deepfashion의 경우 landmark를 통해 옷을 학습하는것이 아니므로, 이에 대한 방안 필요
마네킹을 옷에 맞추는것이 난이도면에서는 쉽지 않을까

#20210823 18차 온라인 회의
딥러닝 분야를 학습을 통한 의류 분류로 선회
기반 모델은 yolov3
그래픽카드가 없어 cuda를 사용하기 힘들어 colab이 제시

#20210827 19차 온라인 회의
detecting된 box 자체를 추출하는데 성공, mediapipe를 도입하여 pose 모델을 익힘
전체적인 프로젝트 계획
1. 진행방향이 이렇다. 보완할 점
2. 상 하의를 잘랐을 때 좌표값을 새로 지정하기 위한 방법이 있을까
3. 구현하려고 하는 매칭 방법은 ~~하다.
////////////////////////
1. 신체 정보를 입력받아 마네킹을 생성하면서, mediapipe의 포즈를 통해 각 landmark의 좌표값을 추출,저장
2. 기준이 되는 신체정보와, 입력받은 사진의 pose를 통해 사진을 resize(어깨, 허리, 무릎 등을 통해)
3. landmark를 대입해놓은 사진과, 원본 사진에 대해 detection 수행
4. 보다 정밀한 옷 추출을 위해 배경을 사람의 조작을 통해 제거
5. 추출한 옷과 landmark를 통해 추출한 것의 비교를 통해 새로운 좌표 등을 매칭
6. 이를 미리 구현해놓은 아바타에 매칭시킨다.
7. 추천
+ 개선할 점
중복 박스저장문제
라벨에 따른 분류 후 저장

#20210908 20차 온라인 회의
class 분류 - 무신사의 분류 기준을 참고
아우터
코트
야상
가죽
블루종
가디건
패딩
데님
블레이져

상의
셔츠
반팔 / 오버핏
긴팔 / 오버핏
후드

바지
청바지 - 일반/ 와이드
슬랙스 - 일반/ 와이드
와이드
일반
추리닝
반바지 


신발
긴양말
구두
부츠
단화
운동화

+여자옷
치마
드레스

pose모델을 사용하여 특정 관절의 각도가 입력될 때 프레임 캡쳐를 구현
추천 알고리즘을 딥러닝이 아닌 머신 러닝의 분야로 선회
-> kaggle의 영화 추천 알고리즘이 기반이 될 예정

#20210913 21차 온라인 회의
31개의 클래스별로 약 250~300장의 데이터 수집
케글의 추천 알고리즘의 작동 방식 학습
목표: 웹캠 실시간 저장, 동작비교 ->분류 ->추천, 모델구현-캡스톤
진행상황: 라벨링(분류), 추천 알고리즘 정해보기
ppt 발표: 발표구성

#20210923 22차 온라인 회의
kaggle의 알고리즘 중, weighted rating에 대한 공식을 옷 추천에 적용하여
우리 팀만의 가중치를 계산하기로 결정
Weighted Rating (WR) =  (vv+m.R)+(mv+m.C) 
v : 영화에 대한 평가 수
m : 차트에 표시되어야 하는 최소 평가 수
R : 영화의 평점
C : 전체 영화에 대한 평균 점수
+ 조회순, 판매순
같이 본 상품?
후기
데이터를 라벨링하는 과정에서 툴을 종료할시 class 번호가 초기화되는 문제 발생

#20210928 23차 온라인 회의
데이터 크롤링을 통해 추천의 기반을 마련
분류 - 상의 하의 아우터 신발
목표하는 진행상황
1. 데이터 분류 기준- 테마에 맞는 옷에 대한 구체적인 설명, 따라서 이러한 과정을 통해 31개로 분류하였고, 이를 토대로 추천 시스템을 완성할것
2. 웹캠을 통해 캡쳐하는 것, 각도를 나타내는 것 결과를 표현 / 가능하다면 영상을 통해 캡쳐하는 것에 관해 시각적으로 보여준다. 
3. 추천 알고리즘을 구성하기 위해 참고하는 케글에 관한 대략적 설명, 핵심이 되는 weighted rating에 대입할 dlc만의 변수
변수를 지정하기 위해 무신사 등의 인터넷 쇼핑물에서 키워드를 크롤링, 이를 전처리하여 나온 결과를 기준으로 삼는다.
4. 이후 과정/ 분류된 데이터를 통해 학습된 weight 파일을 테스트 
크롤링을 통해 선별된 기준에 따라 추천 알고리즘을 가능하다면 실습

#20211006 24차 온라인 회의
리사이즈 문제 해결(랜드마크 좌표 수정 or 라즈베리파이의 초음파 센서 사용을 통해 거리를 조정)-> 10월 말까지 프로토타입 완성 
11월에는 추천 알고리즘, 인터페이스 등을 도입
12월에는 완성도를 올리기 위한 여러 작업
모듈형식으로 프로젝트 진행
+추천을 위해 핏 체형 질감 색 장르 스타일을 고려할 예정

#20211012 25차 온라인 회의
발표자료 준비,
각 추가되거나 변경된 모델 언급

#20211102 26차 온라인 회의
class 번호 초기화 문제 해결 후 colab을 통한 학습 시작
배경 제거 이후 기준이 되는 아바타에 옷을 단순 합성하는 것을 구현
발표준비

#20211116 27차 온라인 회의
yolov3가 학습이 도중에 끊어지거나, 학습이 되더라도 정확성이 현저히 낮은 문제 발생
cfg값을 변경하거나 학습 횟수를 늘려 정확성을 높이고자 함

의상 추천에 대한 알고리즘 변경
메타데이터를 수집하여 특정 옷에 대해 가장 빈도수가 많은 옷을 추천하기로 결정
코디 메타데이터
코디 - 스타일,외투,상의,바지,신발+각각 색상  +파일경로 +날짜
키워드 기준 옷,스타일
나머지옷 추천
현재 날짜 기준 앞뒤로 몇달
2가지버전(옷장+무신사)

#20211119 28차 오프라인 회의
캡스톤 대회, 최종 발표를 위해 필요한 물품 정리
웹캠, 모니터암, 블루투스 리모컨 선정

#20211122 29차 온라인 회의
EEResearch를 위한 발표준비

#20211123 30차 오프라인 회의
yolov4로 메인 모델을 변경하기로 결정
이를 위한 데이터 셔플, 재정비 학습을 위한 코드 수정 후 colab을 통한 학습 도입
추천 알고리즘을 위한 메타데이터 크롤링

#20211130 31차 온라인 회의
k-means clustering을 통한 색 추출 알고리즘 도입
yolov4 학습과정에서 나타난 문제
- avg loss가 1 밑으로 내려가지 않는다
- colab의 경우 느려 학습시간이 150시간이 넘어가는 등의 문제
- 정확성 면에서 시간을 들일수록 개선되나 부정확함

#20211201 32차 온라인 회의
메타데이터에 custom keyword를 도입하여 데이터를 전처리

#20211202~20211208 온, 오프라인 회의
전처리된 메타데이터를 빈도순으로 추출하는 과정 구현
학습 과정에서 시간을 줄이기 위해 iteration을 줄이고
학습이 어려운 신발을 제외한 25개의 class를 먼저 lite모델로 학습 이후 테스트
-> 학습이 완료되었고, map가 83%, 전체적인 모든 class의 정확도가 80% 이상
-> 기존 학습중인 모델과 큰 차이를 보이지 않으므로 폐기
rgb값의 범위를 정하여 총 14개의 색 카테고리를 제작하였고, 이를 추천에 도입
전체 모델 코드를 모듈화하여 UI를 구현

////////////////////
개선점
색 관련 접근성 문제
옷의 경계가 모호한 것/ 
1##학습된 데이터의 정확성 
스트라이프/ 체크무늬 등의 색 분배가 일정한 경우
ui관련은 모델의 접근성
화질이 좋아져 명암 구분이 명확해져 배경 제거 정확성 낮아짐. -> 배경을 단색으로 하는 것도 고려
활용방안//온라인 사이트에 등록된 옷을 입어본 것처럼 할 수 있나 -> 판매자/ 모델의 포즈를 기본 자세로 두고 추출한다면 가능할 것 + 어깨너비 등의 치수를 통해 사이즈를 조절 
-> 다른사람이 입은 옷이 자신의 체형이 맞을까 고려 가능(eeresearch의 피드백 내용 중 하나) //무탠다드의 경우 판매자에 따라  어느 정도 고려 가능 

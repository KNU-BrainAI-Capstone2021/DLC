#20210312 1차 오프라인 회의
개괄적인 내용을 배워서 아직 주제를 정하기 어렵다.
수업에서 배운 자율주행
물체 인식/ 페이지 변형(내용이 적합한가 판단 후)
구문이나 필체를 인식시켜 글을 쓰게 한다/ 맞춤법 검사
코인이나 주식 > 차트 입력으로 다음 결과를 예상 후 대응하는 것
스포츠 매치 승률 > 선수, 전적 등을 근거로 판단
롤의 헬퍼/ 핵
롤토체스 > 덱 조합법으로 상대를 공략
               -입력값이 랜덤(우선적인 가중치를 부여해 순서를 정한다)
               -전적분석 사이트 등을 통해 학습
////
역할분담
메인함수는 다같이
내장함수는 따로 코딩
////
프로젝트 질문사항
학습을 할 때 여러번 코딩하는 과정을 거치는가
이전에 한 사람의 프로젝트 주제?
주제의 방향성
2학기는 어떠한 방향


#20210319 2차 온라인 회의
가중치가 다른 점을 활용
심리검사(ex mbti 등)/ 면접등에서 시뮬레이션 답변
어떠한 단어 선택이 면접 성공에 도움을 주는지 판단
//
주제 관련 질문 방식
//
24일 수요일 오후 5시 IT2-245 교수님 면담 예정

#2021324 교수님 1차 면담 
mediapipe, yolo, tensorflow 등의 패키지에 관해
딥러닝의 분야인 visual(pose, object) / nlp(자연어처리)  등

#20210329 3차 온라인 회의

참고 자료
https://lovit.github.io/nlp/2019/04/30/textrank/
https://excelsior-cjh.tistory.com/93
텍스트 키워드 추출
https://d2.naver.com/helloworld/8344782
글자 인식 예시
https://github.com/nilboy/pixel-recursive-super-resolution
픽셀 복원(Pixel Recursive Super Resolution)
https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix
https://paperswithcode.com/area/computer-vision
cctv
https://github.com/ivaibhavkr/Weapon-Detection-A
https://github.com/Ank-Cha/Social-Distancing-Analyser-COVID-19

가상 피팅 시스템
관상찾기
쓰레기 무단투기 예방
: 손에 든 물체를 두고가는것,
  사람이랑 물체가 일정 거리 이상 떨어지게 되면 투기로 판단
무인 점포

#20210402 교수님 2차 면담
쓰레기 무단투기 : 쓰레기를 특정지을 수 있는 방법 모호, 단순 쓰레기 투기에 관해서만 프로젝트를 진행한다면 너무 단순
무인 점포 : 실제 적용할 시 이점이 크지 않음
cctv관련 : 너무 어렵고 현재 상용화된 기술이므로 x
과제 관련 교수님 링크
https://www.youtube.com/watch?v=-Ff-yq7qquc

*스타일러(가제)*
자동 코디 프로그램
+가능하다면 3d로 구현
  온도 /기온 등에 맞춰 옷을 추천
1학기에는 오브젝트를 이해, 단순한 구현을 목적
- 옷을 사람의 몸에 맞추는것을 목표
2학기/ 방학을 이용해 스타일러 구현

발표
개념적인 부분에 대해 서술
시각적으로 보이는 결과 활용 시 이점
(코딩, 결과값 등)
1.
주제 - 주제 선정이유
이를 위해 오브젝트 디텍션이 필요하다.
오픈소스 플랫폼을 고민 후 yolo 채택 - 이유
이를 통해 ~한 과정으로 진행할 예정
1학기 / 2학기 계획 수립

#20210408 4차 온라인 회의
github readme 작성
yolo의 장점 ap(실시간 object 인식속도 빠름)

참고자료
https://curiousily.com/posts/object-detection-on-custom-dataset-with-yolo-v5-using-pytorch-and-python/
https://youtu.be/mQXOnOdhSOk
https://www.youtube.com/watch?v=hL-gJXgscOc
https://www.youtube.com/watch?v=NM6lrxy0bxs
https://better-today.tistory.com/3
https://www.notion.so/2021-1-82e40203335241c68241a40623c70f12

#20210504 5차 오프라인 회의
중간고사 이후 계획 수립
10주차 발표를 위한 ppt, 대본 제작
yolo를 통해 object detection 간단한 코드 구현

참고자료
https://youtube.com/watch?v=I0RVlki14gI&feature=share
https://youtu.be/N7XyqfhY2lU
https://youtube.com/watch?v=vHs51esvpg0&feature=share
https://bong-sik.tistory.com/16

#20210505 6차 온라인 회의
10주차 발표 개선, 수정, 예상 질문 정리
- 주차 별 계획, 물체인식 이론 등을 추가
- ppt 다듬기

참고자료
https://youtu.be/y03Nbv71CoU

#20210507 10주차 발표
아이디어나 내용에 관한 내용 줄이기
실제로 활동한 내용 발표
깃허브를 여러 사람이서 작성

#20210509 7차 온라인 회의
깃허브에 yolo 테스트 코드, 패키지 업로드
회의록 수정
11차 발표를 위한 ppt, 대본 제작

참고자료
https://twoicefish-secu.tistory.com/121

#20210512 11주차 발표
질문사항
혹시 Object detection 모델에  RCNN Faster RCNN, Yolov1 ~v4까지 엄청 많은데 Yolo의 어떤 점 때문에 프로젝트에서 사용한는 지 이유를 설명 해주실수있을까요?
저는 옷이나 패션 조합을 추천을 해주는 독자적인 알고리즘이 있어야 할 것 같은데 이에 대한 계획이 있으신지 궁금합니다!! 생각해두신 추천 방식이라던가 그런것들이 있으신지 궁금합니다!!
1학기에는 object detection을 수행하고, 2학기에는 옷 사진으로 피팅을 하신다고 하셨는데, 전신 사진과 옷 사진의 합성을 하는 문제를 어떻게 수행하실지 궁금합니다. (모델, 데이터셋 등)
혹시 헤드는 yolo로 detector를 사용하시는데 백본에서는 어떤 모델을 사용하실지 선정된건 있을까요?
피팅의 퀄리티를 위해서 단순 detection 뿐만 아니라 depth estimation 등의 방법을 활용해서 3d 정보를 뽑아내야 할 것이라고 생각하는데 이에 대해선 어떻게 생각하시나요?
각 구문이 어떠한 역할을 하며 가장 중요한 부분은? blob 명령어는 어떠한 것인가?

#20210515 8차 온라인 회의
Faster RCNN, YOLO, SSD
CornerNet, CenterNet 에 대한 구현/ 비교
깃허브 업로드 및 수정
faster rcnn, yolo, ssd 선정 후 비교
각각에 대한 알고리즘 설명/ 비교
~한 이유로 ? 선정 
dataset에 관한 내용 추가 여부
-> 옷에 landmark를 구현하는 것 관련해서 교수님께 질문 후 결정

참고자료
https://ultrakid.tistory.com/22
https://kuklife.tistory.com/123
https://youtu.be/XNRzZkZ-Byg
https://github.com/sejongresearch/FlowerClassification/issues/18
https://jetsonaicar.tistory.com/12
https://liuziwei7.github.io/projects/FashionLandmarks.html
https://github.com/svip-lab/HRNet-for-Fashion-Landmark-Estimation.PyTorch
https://junjiwon1031.github.io/2017/09/08/Single-Shot-Multibox-Detector.html
https://blog.lunit.io/2017/06/01/r-cnns-tutorial/

#20210519 9차 온라인 회의
0515에 상의한 내용을 바탕으로 ppt 제작
기본적으로 object detection에 대해 설명 -backbone, neck, head
detector인 faster rcnn, ssd, yolo를 1-stage, 2-stage를 나누어 기본 개념 설명
각 모델에 대해 동일한 사진으로 detection 결과와 시간을 기록
논문에 기재된 그래프를 바탕으로 실제 실행 시간과 비교하여 메인 모델 선정
yolov3를 선정하였고, 그 이유를 설명
이후 deepfashion2를 yolov3에 학습시켜 옷 데이터를 탐지하려고 함

참고자료
https://arxiv.org/abs/1612.03144
https://velog.io/@hewas1230/ObjectDetection-Architecture
https://nuggy875.tistory.com/20
https://kimcando94.tistory.com/115
https://wordbe.tistory.com/entry/MMDetection-%EB%85%BC%EB%AC%B8-%EC%A0%95%EB%A6%AC-%EB%B0%8F-%EB%AA%A8%EB%8D%B8-%EA%B5%AC%ED%98%84
https://ropiens.tistory.com/33
https://velog.io/@hewas1230/ObjectDetection-Architecture
https://yeomko.tistory.com/17
https://leechamin.tistory.com/221
http://incredible.ai/deep-learning/2018/03/17/Faster-R-CNN/
https://debuggercafe.com/faster-rcnn-object-detection-with-pytorch/
https://towardsdatascience.com/faster-rcnn-object-detection-f865e5ed7fc4
https://blog.lunit.io/2017/06/01/r-cnns-tutorial/
https://ganghee-lee.tistory.com/37
https://herbwood.tistory.com/15
https://taeu.github.io/paper/deeplearning-paper-ssd/
https://junjiwon1031.github.io/2017/09/08/Single-Shot-Multibox-Detector.html
https://cv-tricks.com/object-detection/faster-r-cnn-yolo-ssd/
https://paperswithcode.com/dataset/deepfashion2

#20210520 10차 온라인 회의
21일 발표를 위한 마무리, 다듬기

#20210521 12주차 발표
깃허브 커밋 더 자주
git을 통해 업로드 할때, master를 main으로 변경하는 법
다음 발표에는 deepfashion2에 대한 실습 결과 추가

#20210524 11차 온라인 회의
deepfashion2의 weight파일을 yolov3를 통해 실험
미리 학습된 데이터를 yolo를 통해 탐지하는 것
10/15 성공, 5/15 실패
현재 weight파일은 15000개의 실습을 통해 모델을 탐지하였으므로,
학습이 부족한 것은 아닐까라고 판단하여 이후 과정에서 
putty server를 이용하여 직접 학습시켜보자는 방향으로 프로젝트 진행
사용을 위해 putty 설치 이후 가상환경 dlc 제작, 현재 깃허브에 올라온 코드 server 
실습 내용을 바탕으로 13주차 발표자료 제작



참고자료
https://github.com/simaiden/Clothing-Detection
https://drive.google.com/drive/folders/1b7laIv9-oeh59XSV6aOO50eMKbTGsPoP

#20210527 13주차 발표
yolo는 detecting에 한계점을 가진다.
따라서 이 한계점을 넘어가는 외투나 코트 등등의 의상을 인식하기 못했을 가능성이 크다.
background와 detecting 대상의 색이 같을 경우 landmark를 정확하게 판단하기 어려울 수 있다.
최종적으로 dlc가 가고자 하는 목표에는 3d데이터나 음영을 가진 옷 데이터를 사용해야 되므로 
yolo이외의 다른 모델을 사용하는것을 추천한다.
yolo로 프로젝트 detector를 결정할때 사용한 weight파일과 deepfashion의 weight파일이 다르므로 학습할 때 어떠한
데이터를 사용했는지 분별하기 힘들다.

이러한 문제점들을 해결하기 위해 제시된 방안 
1. 더 많은 데이터를 학습
2. test데이터의 사진 사이즈를 통일시킨다.
3. opencv의 반전 기능을 이용하여 gray등으로 색을 변경시킨다.
 -> 변경하였을 때, 결과물이 원본에 detecting 결과를 추가한 것인지, 변경된 색에 결과를 더한 것인지에 대해
    정확한 판단이 필요하다. 변경된 색으로 결과가 나타난다면 의미있는 detecting x
4. 테스트 빈도를 늘려 정확도를 높인다(목표는 90%이상)
5. 모델을 변경한다(yolo는 영상에서 detecting하는데 더 적합=동적인 모델에서 detecting에 유리)

+코드보단 결과나 그래프, 플로우 차트, 모델링 등에 대해 중점적으로 다루기
 깃허브 커밋을 확인하기 위해 아이디가 보이게 readme 수정
 코드에 주석 등을 달기
 
 #20210530 12차 온라인 회의

fail 추정 이유
deepfashion2 데이터는 대부분 사람이 착용하고 있는 모습이므로 옷 그 자체는 잘 인식하지 못할 수 있는데, 이렇게 생각하는 것이 타당한가?
-> darknet에 학습시킬 데이터셋(deepfashion2)의 양을 늘리려고 하나 yolo에 해당하는 label 파일이 없어 이를 변환하는 과정이 필요, 데이터의 양을 늘려도 해결이 되지 않는다면 사용할 데이터셋을 변경하거나 모델을 변경할 계획

yolo의 문제? deepfashion의 문제?
->모델을 변경하고자 하나, 외장 그래피카드가 없어 서버를 사용해야 하나 cv2오류가 발생, opencv2를 설치하고 import해봐도 그대로 현상유지

테스트 데이터의 입력 사이즈를 통일하면 결과가 좋아지는가?
->사이즈는 blob을 통해 이미 리사이즈 된것으로 추정

색 반전을 통해 landmark를 잡고 detecting을 할 수 있는가?
opencv의 색 반전의 경우 결과값까지 반전이 유지되고, landmark를 따는 과정 자체가 힘들기 때문에 적용 방법을 모르겠다.

이를 해결하기 위해 20210531에 조교님에게 조언을 듣기로 함.

1. 다크넷을 학습시키는법
2. 이를 리눅스 스파이더에 적용하는 법
3. 실습 내용을 보여드리며 데이터셋의 문제인지 yolo의 문제인지 조교님 의견
4. 새로운 데이터셋을 구성할 때 yolo에 맞는 txt파일로 변환하는 법에 대해
5. 이를 통해 구성할 수 있는 발표 내용, 흐름


#20210531 13차 오프라인 회의
큰 기준점 4가지로 나누어 발표를 구성

환경 : 리눅스나 각자
 
model : yolo를 사용하는 방향
yolo의 특징인 빠른 탐색과 역동적인 환경에서 더 잘 detection 할 수 있다는 것을 이용하여 어느정도 발표를 구성
사진의 경우, 단순한 사진만 있는 경우보다 사람이 착용한 경우만 생각하는 방향으로 프로젝트를 진행하는게 어떨까.
확실하게 정해지면, 세부적인 계획를 세워 이를 발표에서 상세하게 프로젝트 방향을 설명 

dataset : dataset에 labelling하여 하는 과정이 복잡하다. 엑셀을 활용하여 ordering한 다음 csv파일을 대입하여 할 수 있지만, 현재 조교님은 추천하지 않는다. 현재 사용하고 있는 deepfashion2를 유지
json파일을 변환하는 것은 가능. 

결과 도출: 조원을 모델로 하여 여러가지 옷을 종류에 맞게 인식하는지 실제 적용가능성을 확인. 테스트 데이터량을 늘려 확실하게 결과를 도출. 20개 테스트는 너무 적다.
힌 옷의 경우, 여러 필터를 적용해보았으나 detecting이 실패하였고, grayscale의 경우 변수에 관한 차원이 달라 실질적인 적용은 어렵다고 판단

코드와 같이 시각적으로 좋지 못한 자료는 거의 배제하고, 현재의 결과나 뱡향성에 대해 집중하여 발표 구성. 실패 또는 잘 안된 부분에 대해서 말하되, 이러한 부분이 많아진다면 발표가 루즈해질 수 있으므로 적당히
최종발표는 현재까지의 진행과, 방향성에 대해서 다루는 것으로
발표 이전 정해진 교수님과의 미팅은 없을 것 같으며, 발표자료 구성 후 한번 더 조교님 피드백 받을 예정
+ 옷을 추천을 받는다고 할때, 이 기준은 주관적인 것이고 해석할 수 있는 여지가 많기 때문에 딥러닝의 범위를 벗어날 수 있다.
  그래서 나온 아이디어는 어느 정도 색을 입력받거나, 특정 조합을 배제하거나, 특정 옷을 미리 조합하여 생각하는 쪽
  어렵다고 판단된다면, numpy의 난수발생을 통해 랜덤하게 옷을 추천하는것도 나쁘지 않은 방법
  

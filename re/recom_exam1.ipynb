{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55695239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "973      The Godfather: Part II\n",
       "8387                 The Family\n",
       "3509                       Made\n",
       "4196         Johnny Dangerously\n",
       "29               Shanghai Triad\n",
       "5667                       Fury\n",
       "2412             American Movie\n",
       "1582    The Godfather: Part III\n",
       "4221                    8 Women\n",
       "2159              Summer of Sam\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset down: https://www.kaggle.com/alsojmc/movie-recommender-systems/data\n",
    "# movies-metadata.csv / links_small.csv\n",
    "\n",
    "#콘텐츠 기반 추천(Content Based Recommender)\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from ast import literal_eval\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel, cosine_similarity\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from surprise import Reader, Dataset, SVD, accuracy\n",
    "\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "\n",
    "md = pd.read_csv('movies_metadata.csv')\n",
    "md.head()\n",
    "md['genres'] = md['genres'].fillna('[]').apply(literal_eval).apply(lambda x: [i['name'] for i in x] if isinstance(x, list) else [])\n",
    "s = md.apply(lambda x: pd.Series(x['genres']), axis=1).stack().reset_index(level=1, drop=True)\n",
    "s.name = 'genre'\n",
    "\n",
    "links_small = pd.read_csv('links_small.csv')\n",
    "links_small = links_small[links_small['tmdbId'].notnull()]['tmdbId'].astype('int')\n",
    "links_small.head()\n",
    "md = md.drop([19730, 29503, 35587])\n",
    "md['id'] = md['id'].astype('int')\n",
    "smd = md[md['id'].isin(links_small)]\n",
    "smd.shape\n",
    "smd = md[md['id'].isin(links_small)]\n",
    "smd.shape\n",
    "smd['tagline'] = smd['tagline'].fillna('')\n",
    "smd['description'] = smd['overview'] + smd['tagline']\n",
    "smd['description'] = smd['description'].fillna('')\n",
    "\n",
    "smd['description'].head()\n",
    "tf = TfidfVectorizer(analyzer='word', ngram_range=(1, 2), min_df=0, stop_words='english')\n",
    "tfidf_matrix = tf.fit_transform(smd['description'])\n",
    "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "cosine_sim[0]\n",
    "smd = smd.reset_index()\n",
    "titles = smd['title']\n",
    "indices = pd.Series(smd.index, index=smd['title'])\n",
    "def get_recommendations(title):\n",
    "    idx = indices[title]\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:31]\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "    return titles.iloc[movie_indices]\n",
    "\n",
    "#example\n",
    "get_recommendations('The Godfather').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f8f6356",
   "metadata": {},
   "outputs": [],
   "source": [
    "#메타 데이터 기반 추천시스템(Metadata Based Recommender)\n",
    "\n",
    "credits = pd.read_csv('credits.csv')\n",
    "keywords = pd.read_csv('keywords.csv')\n",
    "credits['crew'][0]\n",
    "keywords['id'] = keywords['id'].astype('int')\n",
    "credits['id'] = credits['id'].astype('int')\n",
    "md['id'] = md['id'].astype('int')\n",
    "md = md.merge(credits, on='id')\n",
    "md = md.merge(keywords, on='id')\n",
    "smd = md[md['id'].isin(links_small)]\n",
    "smd['cast'] = smd['cast'].apply(literal_eval)\n",
    "smd['crew'] = smd['crew'].apply(literal_eval)\n",
    "smd['keywords'] = smd['keywords'].apply(literal_eval)\n",
    "smd['cast_size'] = smd['cast'].apply(lambda x: len(x))\n",
    "smd['crew_size'] = smd['crew'].apply(lambda x: len(x))\n",
    "def get_director(x):\n",
    "    for i in x:\n",
    "        if i['job'] == 'Director':\n",
    "            return i['name']\n",
    "    return np.nan\n",
    "smd['director'] = smd['crew'].apply(get_director)\n",
    "smd['cast'] = smd['cast'].apply(lambda x: [i['name'] for i in x] if isinstance(x, list) else [])\n",
    "smd['cast'] = smd['cast'].apply(lambda x: x[:3] if len(x) >= 3 else x)\n",
    "smd['keywords'] = smd['keywords'].apply(lambda x: [i['name'] for i in x] if isinstance(x, list) else [])\n",
    "smd['cast'] = smd['cast'].apply(lambda x: [str.lower(i.replace(\" \", \"\")) for i in x])\n",
    "smd['director'] = smd['director'].astype('str').apply(lambda x: str.lower(x.replace(\" \", \"\")))\n",
    "smd['director'] = smd['director'].apply(lambda x: [x, x, x])\n",
    "s = smd.apply(lambda x: pd.Series(x['keywords']), axis=1).stack().reset_index(level=1, drop=True)\n",
    "s.name = 'keyword'\n",
    "s = s.value_counts()\n",
    "s[:5]\n",
    "s = s[s > 1]\n",
    "stemmer = SnowballStemmer('english')\n",
    "def filter_keywords(x):\n",
    "    words = []\n",
    "    for i in x:\n",
    "        if i in s:\n",
    "            words.append(i)\n",
    "    return words\n",
    "smd['keywords'] = smd['keywords'].apply(filter_keywords)\n",
    "smd['keywords'] = smd['keywords'].apply(lambda x: [stemmer.stem(i) for i in x])\n",
    "smd['keywords'] = smd['keywords'].apply(lambda x: [str.lower(i.replace(\" \", \"\")) for i in x])\n",
    "smd['soup'] = smd['keywords'] + smd['cast'] + smd['director'] + smd['genres']\n",
    "smd['soup'] = smd['soup'].apply(lambda x: ' '.join(x))\n",
    "count = CountVectorizer(analyzer='word', ngram_range=(1,2), min_df=0, stop_words='english')\n",
    "count_matrix = count.fit_transform(smd['soup'])\n",
    "cosine_sim = cosine_similarity(count_matrix, count_matrix)\n",
    "smd = smd.reset_index()\n",
    "titles = smd['title']\n",
    "indices = pd.Series(smd.index, index=smd['title'])\n",
    "get_recommendations('The Dark Knight').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1ac27a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d45293d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985c4eca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
